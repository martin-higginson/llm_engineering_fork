{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T05:47:42.458301Z",
     "start_time": "2025-07-02T05:47:41.484533Z"
    }
   },
   "source": [
    "# imports\n",
    "import ollama\n",
    "from IPython.display import Markdown, display, update_display\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T05:47:42.794570Z",
     "start_time": "2025-07-02T05:47:42.788073Z"
    }
   },
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "OLLAMA_HEADERS = {\"Content-Type\": \"application/json\"}"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T05:47:44.077394Z",
     "start_time": "2025-07-02T05:47:42.809330Z"
    }
   },
   "source": [
    "# set up environment\n",
    "!ollama pull llama3.2\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "openai = OpenAI()\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ⠋ \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ⠙ \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ⠹ \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ⠸ \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ⠼ \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ⠴ \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ⠦ \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ⠧ \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest \u001B[K\n",
      "pulling dde5aa3fc5ff: 100% ▕██████████████████▏ 2.0 GB                         \u001B[K\n",
      "pulling 966de95ca8a6: 100% ▕██████████████████▏ 1.4 KB                         \u001B[K\n",
      "pulling fcc5a6bec9da: 100% ▕██████████████████▏ 7.7 KB                         \u001B[K\n",
      "pulling a70ff7e570d9: 100% ▕██████████████████▏ 6.0 KB                         \u001B[K\n",
      "pulling 56bb8bd477a5: 100% ▕██████████████████▏   96 B                         \u001B[K\n",
      "pulling 34bb5ab01051: 100% ▕██████████████████▏  561 B                         \u001B[K\n",
      "verifying sha256 digest \u001B[K\n",
      "writing manifest \u001B[K\n",
      "success \u001B[K\u001B[?25h\u001B[?2026l\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T05:50:44.743546Z",
     "start_time": "2025-07-02T05:50:44.729835Z"
    }
   },
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\"\n",
    "\n",
    "def system_prompt():\n",
    "   return \"\"\"\n",
    "    You are a Python code tutor. You answer questions about the Python language and provide explanations. Give your responses in Markdown format.\"\n",
    "    \"\"\"\n",
    "def user_prompt():\n",
    "    return question\n",
    "\n",
    "def messages():\n",
    "    return [\n",
    "     {\"role\": \"system\", \"content\": system_prompt()},\n",
    "     {\"role\": \"user\", \"content\":user_prompt()}\n",
    "    ]\n",
    "def olama_payload():\n",
    "    return {\n",
    "        \"model\": MODEL_LLAMA,\n",
    "        \"messages\": messages(),\n",
    "        \"stream\": True\n",
    "    }\n",
    "\n",
    "def display_markdown(md):\n",
    "    display(Markdown(md))\n",
    "\n",
    "def display_stream(stream):\n",
    "    for chunk in stream:\n",
    "        if chunk.choices[0].delta.content:\n",
    "            display_markdown(chunk.choices[0].delta.content)\n",
    "            update_display(chunk.choices[0].delta.content, display_id=True)\n",
    "        if chunk.choices[0].delta.role:\n",
    "            display_markdown(chunk.choices[0].delta.role)\n",
    "            update_display(chunk.choices[0].delta.role, display_id=True)\n",
    "        if chunk.choices[0].finish_reason:\n",
    "            display_markdown(chunk.choices[0].finish_reason)\n"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T05:47:54.525078Z",
     "start_time": "2025-07-02T05:47:44.122355Z"
    }
   },
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "\n",
    "stream = openai.chat.completions.create(\n",
    "    model=MODEL_GPT,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt()},\n",
    "        {\"role\": \"user\", \"content\": user_prompt()}\n",
    "      ],\n",
    "    stream=True\n",
    ")\n",
    "display_stream(stream)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Certainly! Let's break down the code you provided:\n\npython\nyield from {book.get(\"author\") for book in books if book.get(\"author\")}\n\n\n### Explanation\n\n1. **Context (`yield from`)**:\n   - The `yield from` statement is used in a generator function to yield all values from an iterable. It effectively delegates part of its operations to another iterator.\n\n2. **Set Comprehension**:\n   - The part inside the curly braces `{}` is a set comprehension. It constructs a set containing certain elements generated by an expression. In this case, it iterates through the `books` collection.\n\n3. **Iteration**:\n   - The expression `for book in books` iterates over each `book` object in the `books` iterable.\n\n4. **Getting the Author**:\n   - The `book.get(\"author\")` method is called on each `book`. This method retrieves the value associated with the key `\"author\"`. If the key does not exist, it returns `None`.\n\n5. **Conditional Filtering**:\n   - The `if book.get(\"author\")` part filters the results. It ensures that only those `book` objects that have a non-None value for the `\"author\"` key are included in the set. Essentially, it excludes any books that do not have an author specified.\n\n6. **Set Creation**:\n   - The result of the set comprehension is a set of unique author names (or `None` values filtered out). This means that even if multiple books are attributed to the same author, the author will only appear once in the resulting set.\n\n### Purpose\n\nThe entire line of code essentially collects and yields all unique authors from a list of book dictionaries (`books`). It ensures that only those authors who are present (i.e., the `\"author\"` key is not `None`) are included. By using `yield from`, it's designed to be part of a generator function that can yield each author's name one at a time.\n\n### Example\n\nHere's a quick example to illustrate:\n\npython\nbooks = [\n    {\"title\": \"Book 1\", \"author\": \"Author A\"},\n    {\"title\": \"Book 2\", \"author\": \"Author B\"},\n    {\"title\": \"Book 3\", \"author\": None},\n    {\"title\": \"Book 4\", \"author\": \"Author A\"},\n]\n\n# Generator function that utilizes the code\ndef get_unique_authors(books):\n    yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n\n# Usage\nfor author in get_unique_authors(books):\n    print(author)\n\n\n### Output:\n\nAuthor A\nAuthor B\n\n\nIn this example, the unique authors \"Author A\" and \"Author B\" are yielded from the generator function, while the book with `None` as an author is ignored."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T05:55:37.767884Z",
     "start_time": "2025-07-02T05:54:54.323096Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get Llama 3.2 to answer\n",
    "\n",
    "# response = requests.post(OLLAMA_API, json=olama_payload, headers=OLLAMA_HEADERS)\n",
    "# print(response.json()['message']['content'])\n",
    "\n",
    "print(messages())\n",
    "response = ollama.chat(model=MODEL_LLAMA, messages=messages())\n",
    "display_markdown(response['message']['content'])"
   ],
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': '\\n    You are a Python code tutor. You answer questions about the Python language and provide explanations. Give your responses in Markdown format.\"\\n    '}, {'role': 'user', 'content': '\\nPlease explain what this code does and why:\\nyield from {book.get(\"author\") for book in books if book.get(\"author\")}\\n'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "**Generator Expression Explanation**\n=====================================\n\nThe given code uses a generator expression to extract author names from a list of books. Here's a breakdown:\n\n```python\nyield from {book.get(\"author\") for book in books if book.get(\"author\")}\n```\n\n*   `books` is assumed to be a list or iterable containing dictionaries, each representing a book.\n*   The dictionary comprehension `{...}` iterates over the `books` collection and filters out any book without an \"author\" key using the `if` condition.\n\n**What does `yield from` do?**\n------------------------------\n\n`yield from` is a Python 3.3+ feature that allows you to delegate iteration to another iterable, such as a generator expression or a list comprehension.\n\nIn this case, the outer `{...}` creates a dictionary with author names as values. The inner generator expression `(...)` yields each author name from the filtered books.\n\nThe `yield from` keyword then \"unfolds\" these yielded values into the outer iteration, effectively yielding all the unique authors in the order they appear in the filtered list of books.\n\n**Example Use Case**\n--------------------\n\nSuppose you have a list of book dictionaries:\n```python\nbooks = [\n    {\"title\": \"Book A\", \"author\": \"Author X\"},\n    {\"title\": \"Book B\", \"author\": None},\n    {\"title\": \"Book C\", \"author\": \"Author Y\"}\n]\n```\n Running the generator expression with `yield from` would yield a dictionary like this:\n```python\n{\n    'Author X': None,\n    'Author Y': None\n}\n```\n\nAs you can see, only books with authors are included in the result.\n\n**Equivalent Code**\n-------------------\n\nFor comparison, here's an equivalent iterative approach using a list to store author names:\n\n```python\nauthors = []\nfor book in books:\n    if book.get(\"author\"):\n        authors.append(book[\"author\"])\nreturn dict.fromkeys(authors)\n```\n\nWhile this code achieves the same result, it's more verbose and less efficient than the original generator expression."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "990f8fcb1db9962e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
